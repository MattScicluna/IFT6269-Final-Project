\section{Supervised baselines for Action Localization}
\label{app:supervised}

\begin{table}[t!]
	\centering
	\resizebox{\linewidth}{!}{
		\begin{tabular}{@{}cccccccc|c@{}}
			\toprule
			\multirow{2}{*}{\textbf{Features}}   & put                       & remove                    & fill                    & open                       & fill                         & open                       & close                       & \multirow{2}{*}{\textbf{Average}} \\
			& \multicolumn{1}{l}{wheel} & \multicolumn{1}{l}{wheel} & \multicolumn{1}{l}{pot} & \multicolumn{1}{l}{oyster} & \multicolumn{1}{l}{coff.cup} & \multicolumn{1}{l}{fridge} & \multicolumn{1}{l|}{fridge} &                                   \\ \midrule
			\multicolumn{1}{l}{\textbf{(1)} CNN + HOF} & \textbf{0.65}                      & 0.68                      & 0.56                    & 0.11                       & 0.91                         & 0.54                       & 0.59                        & 0.58                              \\
			\multicolumn{1}{l}{\textbf{(2)} CNN + IDT}        & \textbf{0.65}                      & \textbf{0.72}                      & \textbf{0.56}                    & \textbf{0.21}                       & \textbf{0.93}                         & \textbf{0.6}                        & \textbf{0.62}                        & \textbf{0.61}                              \\ \bottomrule
		\end{tabular}
	}
	\caption{ \small \label{tab:supexp} Results of supervised baselines for action localization.}
\end{table}

We have run supervised baseline methods with state-of-the-art features. 
To be able to compare numbers with our experiment, we used a leave-one-out technique. 
For each action, we train a binary classifier with SVM on all videos except one. 
Similarly to our setting, we then select the top scoring time interval of the left alone test video. 
We repeat this process for all videos and report the metric used in our paper. 
For baseline \textbf{(1)}, we use the same features we are using in the main paper.
For baseline \textbf{(2)}, we complete our features with all channels of Improved Dense Trajectories (IDT)~\cite{Wang13action}.
Detailed results are given in Table~\ref{tab:supexp}.
We observe that we obtain results that are on par with our weakly supervised baselines (0.55 versus 0.58), therefore demonstrating the potential of using the information of object states for action localization.

