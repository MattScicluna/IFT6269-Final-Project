\vspace{-2mm}
\section{Algorithm}
\vspace{-3mm}

Alg.~\ref{alg:algInfadaptive}
describes the pseudocode for our proposed algorithm to do marginal inference with $\TRW$. 
$\textrm{\textbf{minSpanTree}}$ finds the minimum spanning tree of a
weighted graph, and $\MIfunction(\vmu)$ computes the mutual information of edges of $G$ 
from the pseudomarginals in $\vmu$\footnote{The component $ij$ has value $H(\bmu_i)+H(\bmu_j)-H(\bmu_{ij}).$}
(to perform FW updates over $\vrho$ as in Alg. 2 in~\citet{wainwright2005new}).
It is worthwhile to note that our approach uses three levels of Frank-Wolfe: (1) for the (tightening) optimization
of~$\vrho$ over~$\TREEPOL$, (2) to perform approximate marginal inference, i.e for the optimization of $\vmu$ over $\MARG$, and (3) to perform the correction steps (lines~16 and~23).
%
%
%
\begin{algorithm}[t]
	\caption{Approximate marginal inference over $\MARG$ (solving~\eqref{eqn:upperBoundPartition}). Here $f$ is the negative TRW objective.}
	\label{alg:algInfadaptive}
	\begin{algorithmic}[1]
		\STATE Function \textbf{TRW-Barrier-FW}$(\vrho^{(0)}, \stopCrit, \epsk{\mathrm{init}},\unif)$:
		\STATE \textbf{Inputs:} Edge-appearance probabilities $\vrho^{(0)}$, $\epsk{\mathrm{init}}\leq \frac{1}{4}$ initial contraction of polytope, inner loop stopping criterion $\stopCrit$, fixed reference point $\unif$ in the interior of $\mathcal{M}$. Let $\epsk{-1} = \epsk{\mathrm{init}}$.
		\STATE Let $V := \{\unif\}$ (visited vertices),  $\x^{(0)} = \unif$ \quad (Initialize the algorithm at the uniform distribution) 
	\FOR[\emph{FW outer loop to optimize $\vrho$ over $\TREEPOL$}]{$i=0\dots\MAXRHOITS$}
		\FOR[\emph{FCFW inner loop to optimize $\x$ over $\MARG$}]{$k=0\dots \MAXITS$}
			\STATE Let $\tilde{\theta} = \nabla f(\x^{(k)};\vtheta,\vrho^{(i)})$ \algComment{Compute gradient}
			\STATE Let $\sk \in \displaystyle\argmin_{\vv \in \MARG} \,\, \brangle{\tilde{\theta},\vv}$ \algComment{Run MAP solver to compute FW vertex} 
			\STATE Compute $\gk=\brangle{-\tilde{\theta},\sk-\xk}$ \algComment{Inner loop FW duality gap}
			\IF{$\gk \leq \stopCrit$}
				\STATE \textbf{break} FCFW inner loop  \algComment{$\x^{(k)}$ is $\stopCrit$-optimal}
			\ENDIF
			\STATE $\epsk{k} = \epsk{k-1}$ \algComment{For Adaptive-$\shrinkAmount$: Run Alg. \ref{alg:adaptive_update} to modify $\shrinkAmount$}
			%
			%
			%
			%
			%
			%
			%
			%
			\STATE Let $\skeps = (1-\epsk{k})\sk + \epsk{k} \unif$ and $\dkeps = \skeps - \x^{(k)}$
				\algComment{$\shrinkAmount$-contracted quantities}
			\STATE $\x^{(k+1)} = \arg\min \{ f(\x^{(k)}+\gamma \, \dkeps) : \stepsize \in [0,1] \}$ \algComment{FW step with line search}
			\STATE Update correction polytope: $V := V \cup \{ \sk \}$
			\STATE $\x^{(k+1)} := \CORRECTION(\x^{(k+1)}, V, \epsk{k}, \vrho^{(i)})$ 
			\algComment{optional: correction step}
			\STATE $\x^{(k+1)},V_{\mathrm{search}} := \LOCALSEARCH(\x^{(k+1)}, \sk,\epsk{k}, \vrho^{(i)})$ \algComment{optional: fast MAP solver}
			\STATE Update correction polytope (with vertices from $\LOCALSEARCH$): $V := V \cup \{ V_{\mathrm{search}}\}$
		\ENDFOR
		\STATE $\vrho^{v} \leftarrow \textrm{\textbf{minSpanTree}}(\MIfunction(\x^{(k)}))$ \algComment {FW vertex of the spanning tree polytope}
		\STATE $\vrho^{(i+1)} \leftarrow \vrho^{(i)}+(\frac{i}{i+2})(\vrho^{v}-\vrho^{(i)})$ \algComment{Fixed step-size schedule FW update for $\vrho$ kept in $\mathrm{relint}(\TREEPOL$)}
		\STATE $\x^{(0)}\leftarrow\x^{(k)}$, $\quad \epsk{-1} \leftarrow \epsk{k-1}$ \algComment{Re-initialize for FCFW inner loop}
		\STATE If $i<\MAXRHOITS$ then $\x^{(0)} = \CORRECTION(\x^{(0)},V,\epsk{-1},\vrho^{(i+1)})$ %
	\ENDFOR
	\RETURN $\x^{(0)}$ and $\vrho^{(i)}$
	\end{algorithmic}
\end{algorithm}
%
%
%
%
%
%
We detail a few heuristics that aid practicality. 

%
%

\textbf{Fast Local Search: }
Fast methods for MAP inference such as Iterated Conditional Modes \citep{besag1986statistical} offer a cheap,
low cost alternative to a more expensive combinatorial MAP solver. We warm start the ICM solver
with the last found vertex $\sk$ of the marginal polytope.
The subroutine $\LOCALSEARCH$ (Alg.~\ref{alg:algLocalSearch} in Appendix) performs
a fixed number of FW updates to the pseudomarginals using ICM as the (approximate) MAP solver.  

\textbf{Re-optimizing over the Vertices of~$\mathcal{M}$ (FCFW algorithm): }
As the iterations of FW progress, we keep track of the vertices of the marginal polytope 
found by Alg.~\ref{alg:algInfadaptive} in the set~$V$.
We make use of these vertices in the $\CORRECTION$ subroutine
(Alg.~\ref{alg:algReopt} in Appendix)
which re-optimizes the objective function over (a contraction of) the convex hull of the elements of $V$ (called the correction polytope).
%
%
$\x^{(0)}$ in Alg.~\ref{alg:algInfadaptive} is initialized to the uniform distribution
which is guaranteed to be in~$\MARG$ (and~$\Meps$). After updating~$\vrho$, 
%
we set $\x^{(0)}$ to the approximate minimizer in 
the correction polytope.
%
%
The intuition is that changing $\vrho$ by a small amount
may not substantially modify the optimal $\x^*$ (for the new $\vrho$) and that the new optimum might 
be in the convex hull of the
vertices found thus far. 
If so, $\CORRECTION$ will be able to find it without
resorting to any additional MAP calls. 
This encourages the MAP solver to search 
for new, unique vertices instead of rediscovering old ones. 

\textbf{Approximate MAP Solvers: }
We can swap out the exact MAP solver with an approximate MAP solver. 
%
The primal objective plus the (approximate) duality gap may no longer be an upper bound 
on the log-partition function (black-box MAP solvers could be
considered to optimize over an inner bound to the marginal polytope).
%
%
%
%
%
Furthermore, the gap over $\DOM$ may be negative
if the approximate MAP solver fails to find a direction of descent. Since adaptive-$\shrinkAmount$ requires 
that the gap be positive in Alg.~\ref{alg:adaptive_update},
we take the max over the last gap obtained over the correction
polytope (which is always non-negative) and the computed gap over $\DOM$ as a heuristic. 

Theoretically, one could get similar convergence rates 
as in Thm.~\ref{thm:convergence_fixed_eps_main}
and~\ref{thm:convergence_adaptive_eps_main} using an approximate
MAP solver that has a multiplicative guarantee on the gap (line~8 of Alg.~\ref{alg:algInfadaptive}),
as was done previously for FW-like algorithms (see, e.g., Thm.~C.1 in~\citet{lacoste2012block}).
With an $\epsilon$-additive error guarantee on the MAP solution, one can prove 
similar rates up to a suboptimality error of $\epsilon$.
Even if the approximate MAP solver does not provide an approximation
guarantee, if it returns an  {\em upper bound} on the value of the MAP
assignment (as do branch-and-cut solvers for integer linear programs,
or \cite{SontagEtAl_uai08}),
one can use this to obtain an upper bound on $\log Z$ (see App.~\ref{sec:approx_map_logz}).

%
%
%
%
%
%
