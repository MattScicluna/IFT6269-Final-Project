\section{Preliminaries}

\subsection{Summary of Supplementary Material}
The supplementary material is divided into two parts: 

(1) The first part is dedicated to the exposition
of the theoretical results presented in the main paper. 
Section~\ref{sec:FW_alg} details the variants of the Frank-Wolfe algorithm that we used and analyzed.
Section~\ref{sec:theory_fixed_eps} gives the proof to Theorem~\ref{thm:convergence_fixed_eps_main} (fixed $\shrinkAmount$) while Section~\ref{sec:theory_adaptive_eps} gives the proof to Theorem~\ref{thm:convergence_adaptive_eps_main} (adaptive $\shrinkAmount$). Finally, Section~\ref{sec:trw_properties} applies the convergence theorem to the TRW objective and investigates the relevant constants.

(2) The remainder of the supplementary material provides more information about the experimental setup as well as additional experimental results.

%
%


\subsection{Descent Lemma}
The following descent lemma is proved in \citesup{bertsekas1999nonlinear} (Prop. A24) and is standard for any convergence proof of first order methods. We provide a proof here for completeness. It also highlights the origin of the requirement that we use dual norm pairings between $\x$ and the gradient of $f(\x)$ (because of the generalized Cauchy-Schwartz inequality).
\begin{lemma}
	\label{lem:descent_lemma}
	\textbf{Descent Lemma}
	
	Let $\x_\stepsize :=  \x + \stepsize \dd$ and suppose that $f$ is continuously differentiable on the line segment from $\x$ to ${\x}_{\stepmax}$ for some $\stepmax > 0$.
Suppose that $L = {\sup}_{\alpha \in ]0,\stepmax]} \frac{|| \nabla f(\x+\alpha\dd)-\nabla f(\x)||_*}{||\alpha \dd||}$ is finite, then we have: 
	\begin{equation} \label{eq:descent_lemma}
	f(\x_\stepsize)\leq f(\x)+\stepsize \brangle{\nabla f(\x),\dd} + \frac{\stepsize^2}{2} L||\dd||^2, \quad \forall \stepsize \in [0, \stepmax].
	\end{equation}
\end{lemma}
\begin{proof}
	Let $0 < \stepsize \leq \stepmax$. Denoting $l(\alpha) =f(\x+\alpha\dd)$, we have that:
	\begin{dmath*}
		f(\x_\stepsize)-f(\x)=l(\stepsize)-l(0)=\int_{0}^{\stepsize}\nabla_{\alpha}l(\alpha)d\alpha\\
		=\int_{0}^{\stepsize} \brangle{\dd,\nabla f(\x+\alpha\dd)} d\alpha\\  %
		= \int_{0}^{\stepsize} \brangle{\dd,\nabla f(\x)} d\alpha+ 
		\int_{0}^{\stepsize} \dd^T (\nabla f(\x+\alpha\dd)-\nabla f(\x))d\alpha\\
		\leq \int_{0}^{\stepsize} \brangle{\dd,\nabla f(\x)}d\alpha+ 
		\left|\int_{0}^{\stepsize} \dd^T (\nabla f(\x+\alpha\dd)-\nabla f(\x))\right|d\alpha\\
		\leq \int_{0}^{\stepsize} \brangle{\dd,\nabla f(\x)}d\alpha+ 
		\int_{0}^{\stepsize} ||\dd||\;\;||\nabla f(\x+\alpha\dd)-\nabla f(\x)||_* \, d\alpha\\ %
		= \stepsize\brangle{\dd,\nabla f(\x)} +  
		\int_{0}^{\stepsize} ||\dd||\;\;\frac{||\nabla f(\x+\alpha\dd)-\nabla f(\x)||_*}{\alpha||\dd||}\alpha||\dd|| \, d\alpha\\
		\leq \stepsize\brangle{\dd,\nabla f(\x)} +  
		\int_{0}^{\stepsize} ||\dd||\;\;L||\dd||\alpha \, d\alpha\\
		= \stepsize\brangle{\dd,\nabla f(\x)} +  \frac{L}{2}\stepsize^2||\dd||^2\\
	\end{dmath*}
	Rearranging terms, we get the desired bound.
\end{proof}


\section{Frank-Wolfe Algorithms} \label{sec:FW_alg}

In this section, we present the various algorithms that we use to do fully corrective Frank-Wolfe (FCFW) with adaptive contractions over the domain $\DOM$, as was done in our experiments. 

\subsection{Overview of the Modified Frank-Wolfe Algorithm (FW with Away Steps)}
To implement the approximate correction steps in the fully corrective Frank-Wolfe (FCFW) algorithm, we use the Frank-Wolfe algorithm with away steps~\citepsup{Wolfe:1970wy}, also known as the modified Frank-Wolfe (MFW) algorithm~\citepsup{Guelat:1986fq}. 
We give pseudo-code for MFW in Algorithm~\ref{alg:MFW} (taken from~\citep{lacoste2015MFW}). 
This variant of Frank-Wolfe adds the possibility to do an ``away step'' (see step~5 in Algorithm~\ref{alg:MFW}) in order to avoid the zig zagging phenomenon that slows down Frank-Wolfe when the solution is close to the boundary of the polytope. 
For a strongly convex objective (with Lipschitz continuous gradient), the MFW was known to have asymptotic linear convergence~\citepsup{Guelat:1986fq} and its global linear convergence rate was shown recently~\citep{lacoste2015MFW}, accelerating the slow general sublinear rate of Frank-Wolfe. 
When performing a correction over the convex hull over a (somewhat small) set of vertices of $\DOMeps$, this convergence difference was quite significant in our experiments (MFW converging in a small number of iterations to do an approximate correction vs. FW taking hundreds of iterations to reach a similar level of accuracy). 
We note that the TRW objective is strongly convex when all the edge probabilities are non-zero~\citep{wainwright2005new}; and that it has Lipschitz gradient over $\DOMeps$ (but not $\DOM$).

The gap computed in step~6 of~Algorithm~\ref{alg:MFW} is non-standard; it is a sufficient condition to ensure the global linear convergence of the outer FCFW algorithm when using Algorithm~\ref{alg:MFW} as a subroutine to implement the approximate correction step. See~\citet{lacoste2015MFW} for more details.

The MFW algorithm requires more bookkeeping than standard FW: in addition to the current iterate $\xk$, it also maintains both the active set $\Coreset^{(k)}$ (to search for the ``away vertex'') as well as the barycentric coordinates $\bm{\alpha}^{(k)}$ (to know what are the away step-sizes that ensure feasibility -- see step~13) i.e. $\xk= \sum_{\vv \in \Coreset^{(k)}} \alpha^{(k)}_{\vv} \vv$.

\begin{algorithm}
	\caption{Modified Frank-Wolfe algorithm (FW with Away Steps) -- used for approximate correction}
	\label{alg:MFW}
	\begin{algorithmic}[1]
	\STATE Function \textbf{MFW}$(\x^{(0)}, \bm{\alpha}^{(0)}, \Vertices, \stopCrit)$ to optimize over $\conv(\Vertices)$: 
	\STATE \textbf{Inputs:} Set of atoms $\Vertices$, starting point $\x^{(0)}= \sum_{\vv \in \Coreset^{(0)}} \alpha^{(0)}_{\vv} \vv$ where $\Coreset^{(0)}$ is active set and $\bm{\alpha}^{(0)}$ the active coordinates, stopping criterion $\stopCrit$.
	\FOR{$k=0\dots K$}
		\STATE Let $\s_k \in \displaystyle\argmin_{\vv \in \Vertices} \textstyle\brangle{\nabla f(\x^{(k)}),\vv}$ and $\dd_k^\FW := \s_k - \x^{(k)}$ \qquad~~ \emph{\small(the FW direction)}
		\STATE Let $\vv_k \in \displaystyle\argmax_{\vv \in \Coreset^{(k)} } \textstyle\left\langle \nabla f(\x^{(k)}), \vv \right\rangle$ and $\dd_k^\away := \x^{(k)} - \vv_k$ \qquad \emph{\small(the away direction)}
		\STATE $g_k^\pFW  := \left\langle -\nabla f(\x^{(k)}), \dd_k^\FW + \dd_k^\away\right\rangle$ \qquad \emph{\small(stringent gap is FW + away gap to work better for FCFW)}
		\IF{$g_k^\pFW \leq \stopCrit$}
			\STATE \textbf{return} $\x^{(k)}$, $\bm{\alpha}^{(k)}$, $\Coreset^{(k)}$.
		\ELSE
  				\IF{$\left\langle -\nabla f(\x^{(k)}), \dd_k^\FW\right\rangle  \geq \left\langle -\nabla f(\x^{(k)}), \dd_k^\away\right\rangle$ }
		 		  \STATE $\dd_k :=  \dd_k^\FW$, and $\stepmax := 1$  
		 			     \hspace{20mm}\emph{\small(choose the FW direction)}
		 		  \ELSE
		 		  \STATE $\dd_k :=  \dd_k^\away$, and $\stepmax := \frac{\alpha_{\vv_k}}{(1- \alpha_{\vv_k})}$
		 		  	\hspace{12mm}\emph{\small(choose away direction; maximum feasible step-size)}
		 		  \ENDIF	
		 		  \STATE Line-search: $\stepsize_k \in \displaystyle\argmin_{\stepsize \in [0,\stepmax]} \textstyle f\left(\x^{(k)} + \stepsize \dd_k\right)$
			\STATE Update $\x^{(k+1)} := \x^{(k)} + \stepsize_k \dd_k$
			\STATE Update coordinates $\bm{\alpha}^{(k+1)}$ accordingly (see \citet{lacoste2015MFW}).
			\STATE Update $\Coreset^{(k+1)} := \{\vv \: s.t. \: \alpha^{(k+1)}_{\vv} > 0\}$
		 \ENDIF	
	\ENDFOR
	
	
	\end{algorithmic}
\end{algorithm}


\subsection{Fully Corrective Frank-Wolfe (FCFW) with Adaptive-$\shrinkAmount$}

We give in Algorithm~\ref{alg:adaptive_eps} the pseudo-code to perform fully corrective Frank-Wolfe optimization over $\DOM$ by iteratively optimizing over $\DOMeps$ with adaptive-$\shrinkAmount$ updates.
If $\shrinkAmount$ is kept constant (skipping step 10), then Algorithm~\ref{alg:adaptive_eps} implements the
fixed~$\shrinkAmount$ variant over $\DOMeps$. We describe the algorithm as maintaining the correction set of atoms~$V^{(k+1)}$ over $\DOM$ (rather than $\DOMeps$), as $\shrinkAmount$ is constantly changing. One can easily move back and forth between $V^{(k+1)}$ and its contraction $V_\shrinkAmount = (1-\epsk{k})V^{(k+1)} + \epsk{k} \unif$, and so we note that an efficient implementation might work with either representation cheaply (for example, by storing only $V^{(k+1)}$ and $\shrinkAmount$, not the perturbed version of the correction polytope). The approximate correction over $V_\shrinkAmount$ is implemented using the MFW algorithm described in Algorithm~\ref{alg:MFW}, which requires a barycentric representation $\bm{\alpha}^{(k)}$ of the current iterate $\xk$ over the correction polytope $V_\shrinkAmount$. Our notation in Algorithm~\ref{alg:adaptive_eps} uses the elements of $\Vertices$ as indices, rather than their contracted version; that is, we maintain the property that $\xk = \sum_{\vv \in \Vertices} \alpha_{\vv}^{(k)} [(1-\epsk{k}) \vv + \epsk{k} \unif]$. As $V_\shrinkAmount$ changes when $\shrinkAmount$ changes, we need to update the barycentric representation of $\xk$ accordingly -- this is done in step~11 with the following equation. Suppose that we decrease $\shrinkAmount$ to $\shrinkAmount'$. Then the old coordinates $\bm{\alpha}$ can be updated to new coordinates $\bm{\alpha}'$ for the new contraction polytope as follows:
\begin{align}
\begin{split} \label{eq:alpha_update}
\alpha'_{\vv} &= \alpha_{\vv} \frac{1-\shrinkAmount}{1-\shrinkAmount'} \qquad \text{for} \quad \vv \in \Vertices \setminus \{\unif \}, \\
\alpha'_{\unif} &= 1-\sum_{\vv \neq \unif} \alpha'_{\vv}.
\end{split}
\end{align} 
This ensures that $\sum_{\vv} \alpha_{\vv} \vv_{(\shrinkAmount)} = \sum_{\vv} \alpha'_{\vv} \vv_{(\shrinkAmount')}$, where $\vv_{(\shrinkAmount)} := (1-\shrinkAmount) \vv + \shrinkAmount \unif$, and that the coordinates form a valid convex combination (assuming that $\shrinkAmount' \leq \shrinkAmount$), as can be readily verified.

%
\begin{algorithm}
	\caption{Optimizing $f$ over $\DOM$ using Fully Corrective Frank-Wolfe (FCFW) with Adaptive-$\shrinkAmount$ Algorithm.}
	\label{alg:adaptive_eps}
	\begin{algorithmic}[1]
		\STATE \textbf{FCFW}$(\x^{(0)}, \Vertices, \stopCrit, \epsk{\mathrm{init}})$
		\STATE \textbf{Inputs:} Set of atoms $\Vertices$ so that $\DOM = \conv({\Vertices})$, active set $\Coreset^{(0)}$, starting point $\x^{(0)}= \sum_{\vv \in \Coreset^{(0)}} \alpha^{(0)}_{\vv}  [(1-\epsk{\mathrm{init}})\vv + \epsk{\mathrm{init}} \unif]$ where $\bm{\alpha}^{(0)}$ are the active coordinates, $\epsk{\mathrm{init}}\leq \frac{1}{4}$ describes the initial contraction of the polytope, stopping criterion $\stopCrit$, $\unif$ is a fixed reference point in the relative interior of $\DOM$.
		\STATE Let $V^{(0)} := \Coreset^{(0)}$ \quad (optionally, a bigger $V^{(0)}$ could be passed as argument for a warm start), $\epsk{-1} := \epsk{\mathrm{init}}$ 
	\FOR{$k=0\dots K$}
		\STATE Let $\sk \in \displaystyle\argmin_{\vv \in \Vertices} \textstyle\innerProd{\nabla f(\x^{(k)})}{\vv}$ \qquad \emph{\small(the FW vertex)} 
		\STATE Compute $\gk=\brangle{-\nabla f(\xk),\sk-\xk}$ \quad \emph{\small(FW gap)} 
		\IF{$\gk \leq \stopCrit$}
			\STATE \textbf{return} $\x^{(k)}$
		\ENDIF
%
%
%
%
%
%
%
		\STATE Let $\epsk{k}$ be $\epsk{k-1}$ updated according to Algorithm~\ref{alg:adaptive_update}.
		\STATE Update $\bm{\alpha}^{(k)}$ accordingly (using~\eqref{eq:alpha_update})
		\STATE Let $\skeps := (1-\epsk{k})\sk + \epsk{k} \unif$ 
		\STATE Let $\dd_k^\FW := \skeps - \x^{(k)}$ 
		\STATE Line-search: $\stepsize_k \in \displaystyle\argmin_{\stepsize \in [0,1]} \textstyle f\left(\x^{(k)} + \stepsize \dd_k^\FW\right)$
		\STATE Set $\x^{(\mathrm{temp)}} := \x^{(k)} + \stepsize_k  \dd_k^\FW$  \algComment{initialize correction to the update after a FW step with line search}
		\STATE $\bm{\alpha}^{(\mathrm{temp})} = (1-\stepsize_k) \bm{\alpha}^{(k)}$
		\STATE $\alpha_{\sk}^{(\mathrm{temp)}} \leftarrow \alpha_{\sk}^{(\mathrm{temp)}} + \stepsize_k$ \algComment{update coordinates according to the FW step}
		\STATE Update (non-contracted) correction polytope: $V^{(k+1)} := V^{(k)} \cup \{ \sk \}$
		\STATE Let $V_\shrinkAmount = (1-\epsk{k})V^{(k+1)} + \epsk{k} \unif$ \algComment{contracted correction polytope}
		\STATE $\x^{(k+1)}\!\!$, $\bm{\alpha}^{(k+1)} := \textbf{\textrm{MFW}}(\x^{(\mathrm{temp)}},\bm{\alpha}^{(\mathrm{temp})}, V_\shrinkAmount, \stopCrit)$ \quad \emph{\small (approximate correction step on $V_\shrinkAmount$ using MFW)}
	\ENDFOR
	\end{algorithmic}
\end{algorithm}



%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
