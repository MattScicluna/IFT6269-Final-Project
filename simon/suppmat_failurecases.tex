\section{Failure cases}
\label{app:failcases}

\begin{figure}[t!]
	\centering
	\includegraphics[width=\linewidth]{figs/failmode.pdf}
	\caption{
		Typical failure cases for ``\textit{removing car wheel}'' (top) and
		`Ì€`\textit{fill coffee cup}'' (middle, bottom) actions. 
		Yellow indicates correct predictions; red indicates mistakes. Top: the removed wheel is incorrectly localized (right). 
		Middle: the ``empty cup'' is incorrectly
		localized (left). 
		Bottom: In this case, both object tracklets are annotated as ``\textit{ambiguous}'' in the ground truth as they occur during
		the pouring action and hence the predictions, while they appear
		reasonable, are deemed incorrect.
	}
	\vspace{-2mm} %
	\label{fig:failcases}
\end{figure}	

We observed two main types of failures, illustrated in Figure~\ref{fig:failcases}. 
The first one occurs when a false positive object detection consistently satisfies the hypothesis of our model in multiple videos (the top two rows in Figure~\ref{fig:failcases}).
The second typical failure mode is due to ambiguous labels (bottom row in Figure~\ref{fig:failcases}). 
This highlights the difficulty in
annotating ground truth for long actions such as ``\textit{pouring coffee}".